# optimization_for_research

# proposed
パラメータを動かした場合の比較

他と比較

MLPNETの初期展

full dimension
・gradient descent ラインサーチ付きを実装
・accelerated gradient descent　リスタートつき
・Marumo AGD 実装
・newton
・BFGS
・Limited memory bfgs

subspace
・subspace gradient descent
・subspace newton
・Lee et al.[1, 2]’s method　これ追加
・RS-RNM 追加
・Kovalev et al.’s method
・propsoed 

fullspace hessian x
subspace hessian o

